{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes accelerate transformers datasets\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum -qq"
      ],
      "metadata": {
        "id": "TFt8JP0pr4T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì´ˆê¸° ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "import os\n",
        "import json\n",
        "from google.colab import userdata, drive\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import huggingface_hub\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    recall_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams['font.family'] = 'NanumGothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "fm._load_fontmanager(try_read_cache=False)\n",
        "\n",
        "# ë°ì´í„° ë¡œë“œ\n",
        "drive.mount('/content/drive')\n",
        "df_NLP = pd.read_csv('/content/drive/MyDrive/ë¸Œë¼ì§ˆ ì´ì»¤ë¨¸ìŠ¤/project_olist_ecommerce/project_dataset/olist_reviews_clean.csv')\n",
        "df_NLP.info()\n",
        "n_categories = df_NLP['product_category_name'].nunique()\n",
        "print(n_categories)\n",
        "\n",
        "# í´ë˜ìŠ¤ ë¶„í¬\n",
        "class_dist = df_NLP['review_score'].value_counts().sort_index()\n",
        "print(class_dist)\n",
        "print(f\"ë¹„ìœ¨:{(class_dist / len(df_NLP) * 100).round(2)}\")\n",
        "\n",
        "# ë¶ˆê· í˜• ì²´í¬\n",
        "max_ratio = class_dist.max() / class_dist.min()\n",
        "print(f\"ë¶ˆê· í˜• ë¹„ìœ¨: {max_ratio:.2f}ë°°\")\n",
        "if max_ratio > 3: #ì‚­ì œ\n",
        "    print(\"í´ë˜ìŠ¤ ë¶ˆê· í˜• â†’ class_weight í•„ìš”\")\n",
        "\n",
        "# ë¦¬ë·°ë³„ ê¸¸ì´ ê³„ì‚°\n",
        "review_lengths = df_NLP['review_comment_message'].str.len()\n",
        "print(f\"ìµœëŒ€ ê¸¸ì´: {review_lengths.max()}\")\n",
        "\n",
        "# ë ˆì´ë¸” ìƒì„±\n",
        "df_NLP['sentiment'] = df_NLP['review_score'] - 1  # 1â†’0, 2â†’1, 3â†’2, 4â†’3, 5â†’4\n",
        "\n",
        "print(\"ë ˆì´ë¸” ë§¤í•‘ í™•ì¸\")\n",
        "mapping_check = df_NLP.groupby('review_score')['sentiment'].unique()\n",
        "for score, sent in mapping_check.items():\n",
        "    print(f\"review_score {score} â†’ sentiment {sent[0]}\")\n",
        "\n",
        "# Phase 1-2: Train/Val/Test ë¶„í•  (7:1.5:1.5)\n",
        "train_df, temp_df = train_test_split(\n",
        "    df_NLP,\n",
        "    test_size=0.3,\n",
        "    stratify=df_NLP['sentiment'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Temp: Val(15%) / Test(15%)\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df['sentiment'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_df):,}ê°œ ({len(train_df)/len(df_NLP)*100:.1f}%)\")\n",
        "print(f\"Val:   {len(val_df):,}ê°œ ({len(val_df)/len(df_NLP)*100:.1f}%)\")\n",
        "print(f\"Test:  {len(test_df):,}ê°œ ({len(test_df)/len(df_NLP)*100:.1f}%)\")\n",
        "\n",
        "# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
        "print(\"Train í´ë˜ìŠ¤ ë¶„í¬:\")\n",
        "print(train_df['sentiment'].value_counts().sort_index())\n",
        "\n",
        "# í† í° ê¸¸ì´ í™•ì¸\n",
        "# Hugging Face ë¡œê·¸ì¸\n",
        "huggingface_hub.login(token=userdata.get('NLP_TOKEN'))\n",
        "MODEL_ID = \"tabularisai/multilingual-sentiment-analysis\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "# ìƒ˜í”Œ 1000ê°œë¡œ í† í° ê¸¸ì´ ì¸¡ì •\n",
        "sample_texts = df_NLP['review_comment_message'].sample(1000, random_state=42)\n",
        "token_lengths = [len(tokenizer.encode(text, add_special_tokens=True)) for text in sample_texts]\n",
        "\n",
        "print(f\"í† í° ê¸¸ì´ í†µê³„:\")\n",
        "print(f\"í‰ê· : {sum(token_lengths)/len(token_lengths):.1f}\")\n",
        "print(f\"95%: {sorted(token_lengths)[int(len(token_lengths)*0.95)]}\")\n",
        "print(f\"99%: {sorted(token_lengths)[int(len(token_lengths)*0.99)]}\")\n",
        "\n",
        "# max_length ê¶Œì¥\n",
        "max_length = sorted(token_lengths)[int(len(token_lengths)*0.95)]\n",
        "if max_length <= 128:\n",
        "    print(f\"max_length: 128\")\n",
        "else:\n",
        "    print(f\"max_length: {max_length}\")\n",
        "\n",
        "# ë°ì´í„° ì €ì¥\n",
        "BASE_PATH = '/content/drive/MyDrive/ë¸Œë¼ì§ˆ ì´ì»¤ë¨¸ìŠ¤/NLP'\n",
        "SAVE_PATH = f'{BASE_PATH}/processed'\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "train_df.to_csv(f'{SAVE_PATH}/train.csv', index=False)\n",
        "val_df.to_csv(f'{SAVE_PATH}/val.csv', index=False)\n",
        "test_df.to_csv(f'{SAVE_PATH}/test.csv', index=False)\n"
      ],
      "metadata": {
        "id": "h4KpjSzUIR5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# ë°©ë²•: ì´ëª¨ì§€ í™•ì¸\n",
        "\n",
        "# ì´ëª¨ì§€ íŒ¨í„´ (Unicode ë²”ìœ„)\n",
        "emoji_pattern = re.compile(\n",
        "    \"[\"\n",
        "    \"\\U0001F600-\\U0001F64F\"  # ê°ì • í‘œí˜„ (ğŸ˜€-ğŸ™)\n",
        "    \"\\U0001F300-\\U0001F5FF\"  # ê¸°í˜¸ & í”½í† ê·¸ë¨ (ğŸŒ€-ğŸ—¿)\n",
        "    \"\\U0001F680-\\U0001F6FF\"  # êµí†µ & ì§€ë„ (ğŸš€-ğŸ›¿)\n",
        "    \"\\U0001F1E0-\\U0001F1FF\"  # êµ­ê¸° (ğŸ‡¦-ğŸ‡¿)\n",
        "    \"\\U00002702-\\U000027B0\"  # Dingbats (âœ‚-â°)\n",
        "    \"\\U000024C2-\\U0001F251\"  # ê¸°íƒ€\n",
        "    \"]+\",\n",
        "    flags=re.UNICODE\n",
        ")\n",
        "\n",
        "# ì „ì²´ ë°ì´í„° í™•ì¸\n",
        "has_emoji = test_df['review_comment_message'].apply(\n",
        "    lambda x: bool(emoji_pattern.search(str(x)))\n",
        ")\n",
        "\n",
        "print(\"ì´ëª¨ì§€ í¬í•¨ ì—¬ë¶€\")\n",
        "print(f\"ì´ ë¦¬ë·°:        {len(test_df):,}ê°œ\")\n",
        "print(f\"ì´ëª¨ì§€ í¬í•¨:    {has_emoji.sum():,}ê°œ ({has_emoji.mean()*100:.2f}%)\")\n",
        "print(f\"ì´ëª¨ì§€ ì—†ìŒ:    {(~has_emoji).sum():,}ê°œ ({(~has_emoji).mean()*100:.2f}%)\")\n",
        "\n",
        "# ë°©ë²• 3: ìƒ˜í”Œë¡œ í™•ì¸ (ë¹ ë¥¸ ì²´í¬)\n",
        "import random\n",
        "\n",
        "# ì´ëª¨ì§€ í¬í•¨ ë¦¬ë·°ë§Œ ì¶”ì¶œ\n",
        "emoji_reviews = test_df[test_df['review_comment_message'].apply(\n",
        "    lambda x: bool(emoji_pattern.search(str(x)))\n",
        ")]\n",
        "\n",
        "if len(emoji_reviews) > 0:\n",
        "    print(\"=\"*60)\n",
        "    print(f\"ì´ëª¨ì§€ í¬í•¨ ë¦¬ë·° ìƒ˜í”Œ ({len(emoji_reviews)}ê°œ ì¤‘ 10ê°œ)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    samples = emoji_reviews.sample(min(10, len(emoji_reviews)), random_state=42)\n",
        "\n",
        "    for idx, (_, row) in enumerate(samples.iterrows(), 1):\n",
        "        print(f\"\\n{idx}. ê°ì„±: {row['sentiment']} | ì˜ˆì¸¡: {row.get('predicted', 'N/A')}\")\n",
        "        print(f\"   {row['review_comment_message'][:150]}...\")\n",
        "else:\n",
        "    print(\"âœ… ì´ëª¨ì§€ í¬í•¨ ë¦¬ë·° ì—†ìŒ\")"
      ],
      "metadata": {
        "id": "rl_74TS173Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-1: Test Set ë¡œë“œ\n",
        "SAVE_PATH = '/content/drive/MyDrive/ë¸Œë¼ì§ˆ ì´ì»¤ë¨¸ìŠ¤/NLP/processed'\n",
        "test_df = pd.read_csv(f'{SAVE_PATH}/test.csv')\n",
        "\n",
        "print(f\"Test set: {len(test_df):,}ê°œ\")\n",
        "print(f\"í´ë˜ìŠ¤ ë¶„í¬:\\n{test_df['sentiment'].value_counts().sort_index()}\")\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# 2-2: ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡  ì¤€ë¹„\n",
        "# Hugging Face ë¡œê·¸ì¸\n",
        "huggingface_hub.login(token=userdata.get('NLP_TOKEN'))\n",
        "MODEL_ID = \"tabularisai/multilingual-sentiment-analysis\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 2-3: Test Set ì¶”ë¡  (ë°°ì¹˜ ì²˜ë¦¬)\n",
        "def predict_batch(texts, batch_size=32):\n",
        "    predictions = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"ì¶”ë¡  ì¤‘\"):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=128\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "            predictions.extend(preds)\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "# ì¶”ë¡  ì‹¤í–‰\n",
        "test_texts = test_df['review_comment_message'].tolist()\n",
        "y_true = test_df['sentiment'].values\n",
        "y_pred = predict_batch(test_texts, batch_size=32)\n",
        "\n",
        "print(f\"\\nì¶”ë¡  ì™„ë£Œ: {len(y_pred):,}ê°œ\")\n",
        "\n",
        "# 2-4: F1-score ê³„ì‚°\n",
        "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "accuracy = (y_true == y_pred).mean()\n",
        "\n",
        "print(\"Baseline ì„±ëŠ¥\")\n",
        "print(f\"Accuracy:        {accuracy:.4f}\")\n",
        "print(f\"F1 (Weighted):   {f1_weighted:.4f}\")\n",
        "print(f\"F1 (Macro):      {f1_macro:.4f}\")\n",
        "print(f\"\\nëª©í‘œ F1 (Weighted): {f1_weighted + 0.05:.4f} (+5%)\")\n",
        "\n",
        "# 2-5: í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ í™•ì¸\n",
        "print(\"í´ë˜ìŠ¤ë³„ ì„±ëŠ¥\")\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=['Very Negative', 'Negative', 'Neutral', 'Positive', 'Very Positive'],\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "# 2-6: Confusion Matrix ì‹œê°í™”\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    xticklabels=['0', '1', '2', '3', '4'],\n",
        "    yticklabels=['0', '1', '2', '3', '4']\n",
        ")\n",
        "plt.title('Baseline Confusion Matrix', fontsize=14, weight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "\n",
        "# ì €ì¥\n",
        "RESULT_PATH = f'{SAVE_PATH}/results'\n",
        "os.makedirs(RESULT_PATH, exist_ok=True)\n",
        "plt.savefig(f'{RESULT_PATH}/baseline_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# 2-7: ê²°ê³¼ ì €ì¥ (JSON)\n",
        "per_class_f1 = f1_score(y_true, y_pred, average=None)\n",
        "\n",
        "baseline_results = {\n",
        "    \"model\": MODEL_ID,\n",
        "    \"test_samples\": len(test_df),\n",
        "    \"accuracy\": float(accuracy),\n",
        "    \"f1_weighted\": float(f1_weighted),\n",
        "    \"f1_macro\": float(f1_macro),\n",
        "    \"target_f1\": float(f1_weighted + 0.05),\n",
        "    \"class_distribution\": test_df['sentiment'].value_counts().sort_index().to_dict(),\n",
        "    \"per_class_f1\": {\n",
        "        str(i): float(per_class_f1[i])\n",
        "        for i in range(5)\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(f'{RESULT_PATH}/baseline_metrics.json', 'w') as f:\n",
        "    json.dump(baseline_results, f, indent=2)\n",
        "\n",
        "# ìš”ì•½ ì¶œë ¥\n",
        "print(f\"Baseline F1 (Weighted): {f1_weighted:.4f}\")\n",
        "print(f\"ëª©í‘œ F1 (LoRA í›„):      {f1_weighted + 0.05:.4f}\")\n",
        "print(f\"ê°œì„  í•„ìš”ëŸ‰:            +{0.05:.4f} ({0.05/f1_weighted*100:.1f}%)\")\n",
        "\n",
        "test_df.info()"
      ],
      "metadata": {
        "id": "47itjgpzVUPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Phase 3: LoRA íŒŒì¸íŠœë‹ íŒŒì´í”„ë¼ì¸\n",
        "# ============================================\n",
        "!pip install -q peft accelerate\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from datasets import Dataset\n",
        "\n",
        "# ============================================\n",
        "# 3-1: Train/Val ë°ì´í„° ë¡œë“œ\n",
        "# ============================================\n",
        "SAVE_PATH = '/content/drive/MyDrive/ë¸Œë¼ì§ˆ ì´ì»¤ë¨¸ìŠ¤/NLP/processed'\n",
        "train_df = pd.read_csv(f'{SAVE_PATH}/train.csv')\n",
        "val_df = pd.read_csv(f'{SAVE_PATH}/val.csv')\n",
        "\n",
        "print(f\"Train: {len(train_df):,}ê°œ\")\n",
        "print(f\"Val:   {len(val_df):,}ê°œ\")\n",
        "print(f\"\\nTrain í´ë˜ìŠ¤ ë¶„í¬:\")\n",
        "print(train_df['sentiment'].value_counts().sort_index())\n",
        "\n",
        "# ============================================\n",
        "# 3-2: Class Weight ê³„ì‚°\n",
        "# ============================================\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_df['sentiment']),\n",
        "    y=train_df['sentiment']\n",
        ")\n",
        "\n",
        "print(f\"\\nClass Weights:\")\n",
        "for i, weight in enumerate(class_weights):\n",
        "    count = (train_df['sentiment'] == i).sum()\n",
        "    print(f\"  í´ë˜ìŠ¤ {i}: {weight:.2f} (ìƒ˜í”Œ {count}ê°œ)\")\n",
        "\n",
        "# Tensorë¡œ ë³€í™˜\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to('cuda')\n",
        "\n",
        "# ============================================\n",
        "# 3-3: ë°ì´í„°ì…‹ í† í°í™”\n",
        "# ============================================\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "# Hugging Face Dataset í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'text': train_df['review_comment_message'].tolist(),\n",
        "    'label': train_df['sentiment'].tolist()\n",
        "})\n",
        "\n",
        "val_dataset = Dataset.from_dict({\n",
        "    'text': val_df['review_comment_message'].tolist(),\n",
        "    'label': val_df['sentiment'].tolist()\n",
        "})\n",
        "\n",
        "# í† í°í™”\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "print(f\"\\nâœ… í† í°í™” ì™„ë£Œ\")\n",
        "\n",
        "# ============================================\n",
        "# 3-4: LoRA Config ì„¤ì •\n",
        "# ============================================\n",
        "# ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ\n",
        "MODEL_ID = \"tabularisai/multilingual-sentiment-analysis\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)\n",
        "\n",
        "# LoRA ì„¤ì •\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_lin\", \"v_lin\"],  # DistilBERT attention\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_CLS\n",
        ")\n",
        "\n",
        "# LoRA ëª¨ë¸ ìƒì„±\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# ============================================\n",
        "# 3-5: Custom Trainer (Class Weight ì ìš©)\n",
        "# ============================================\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Class weight ì ìš©í•œ Loss\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# ============================================\n",
        "# 3-6: Metrics ê³„ì‚° (Macro-F1 + Per-class Recall)\n",
        "# ============================================\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Macro F1 (Early stopping ê¸°ì¤€)\n",
        "    macro_f1 = f1_score(labels, preds, average='macro')\n",
        "\n",
        "    # Weighted F1 (ì‹¤ë¬´ ì„±ëŠ¥)\n",
        "    weighted_f1 = f1_score(labels, preds, average='weighted')\n",
        "\n",
        "    # Per-class Recall (í´ë˜ìŠ¤ 4 ëª¨ë‹ˆí„°ë§)\n",
        "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
        "\n",
        "    return {\n",
        "        'macro_f1': macro_f1,\n",
        "        'weighted_f1': weighted_f1,\n",
        "        'recall_0': recall_per_class[0],\n",
        "        'recall_1': recall_per_class[1],\n",
        "        'recall_2': recall_per_class[2],\n",
        "        'recall_3': recall_per_class[3],\n",
        "        'recall_4': recall_per_class[4],  # â­ ê°€ì¥ ì¤‘ìš”\n",
        "    }\n",
        "\n",
        "# ============================================\n",
        "# 3-7: Training Arguments\n",
        "# ============================================\n",
        "CHECKPOINT_PATH = f'{SAVE_PATH}/checkpoints'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=CHECKPOINT_PATH,\n",
        "\n",
        "    # í•™ìŠµ íŒŒë¼ë¯¸í„°\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # í‰ê°€ & ì €ì¥ ì „ëµ\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "\n",
        "    # Best model ê´€ë¦¬\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",  # Macro-F1 ê¸°ì¤€\n",
        "    greater_is_better=True,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    # ëª¨ë‹ˆí„°ë§\n",
        "    logging_steps=50,\n",
        "    logging_dir=f'{CHECKPOINT_PATH}/logs',\n",
        "\n",
        "    # ê¸°íƒ€\n",
        "    fp16=True,  # ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# 3-8: Trainer ìƒì„±\n",
        "# ============================================\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(\n",
        "        early_stopping_patience=3,\n",
        "        early_stopping_threshold=0.001\n",
        "    )]\n",
        ")"
      ],
      "metadata": {
        "id": "bpW5rUpeVnSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 4: ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦\n",
        "trainer.train()\n",
        "\n",
        "# Loss ê·¸ë˜í”„: í•™ìŠµ ë¡œê·¸ ì¶”ì¶œ\n",
        "log_history = trainer.state.log_history\n",
        "train_logs = [x for x in log_history if 'loss' in x and 'eval_loss' not in x]\n",
        "eval_logs = [x for x in log_history if 'eval_loss' in x]\n",
        "\n",
        "# ê·¸ë˜í”„ ìƒì„±\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss ê·¸ë˜í”„\n",
        "axes[0].plot([x['step'] for x in train_logs], [x['loss'] for x in train_logs], label='Train Loss')\n",
        "axes[0].plot([x['step'] for x in eval_logs], [x['eval_loss'] for x in eval_logs], label='Eval Loss', marker='o')\n",
        "axes[0].set_xlabel('Steps')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training & Validation Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Macro-F1 ê·¸ë˜í”„\n",
        "axes[1].plot([x['step'] for x in eval_logs], [x['eval_macro_f1'] for x in eval_logs], marker='o', color='green')\n",
        "axes[1].set_xlabel('Steps')\n",
        "axes[1].set_ylabel('Macro-F1')\n",
        "axes[1].set_title('Validation Macro-F1')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULT_PATH}/training_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# 4-3: Test Set í‰ê°€\n",
        "print(\"Test Set ìµœì¢… í‰ê°€\")\n",
        "\n",
        "# Test ë°ì´í„° ë¡œë“œ\n",
        "test_df = pd.read_csv(f'{SAVE_PATH}/test.csv')\n",
        "test_dataset = Dataset.from_dict({\n",
        "    'text': test_df['review_comment_message'].tolist(),\n",
        "    'label': test_df['sentiment'].tolist()\n",
        "})\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# ì¶”ë¡ \n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = test_df['sentiment'].values\n",
        "\n",
        "# ì„±ëŠ¥ ê³„ì‚°\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "accuracy = (y_true == y_pred).mean()\n",
        "recall_per_class = recall_score(y_true, y_pred, average=None)\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(f\"\\nAccuracy:        {accuracy:.4f}\")\n",
        "print(f\"Weighted F1:     {weighted_f1:.4f}\")\n",
        "print(f\"Macro F1:        {macro_f1:.4f}\")\n",
        "\n",
        "print(f\"\\ní´ë˜ìŠ¤ë³„ Recall:\")\n",
        "for i in range(5):\n",
        "    print(f\"  í´ë˜ìŠ¤ {i}: {recall_per_class[i]:.4f}\")\n",
        "\n",
        "# 4-4: Baseline ë¹„êµ\n",
        "print(\"Baseline vs LoRA ë¹„êµ\")\n",
        "\n",
        "baseline_recall_4 = 0.0892  # Phase 2 ê²°ê³¼\n",
        "lora_recall_4 = recall_per_class[4]\n",
        "\n",
        "print(f\"\\nâ­ Recall(4) ê°œì„ :\")\n",
        "print(f\"  Baseline: {baseline_recall_4:.4f}\")\n",
        "print(f\"  LoRA:     {lora_recall_4:.4f}\")\n",
        "print(f\"  ê°œì„ ëŸ‰:   +{lora_recall_4 - baseline_recall_4:.4f} ({(lora_recall_4/baseline_recall_4 - 1)*100:.1f}%)\")\n",
        "\n",
        "if lora_recall_4 >= 0.40:\n",
        "    print(f\"\\nâœ… ëª©í‘œ ë‹¬ì„±! (Recall 4 â‰¥ 0.40)\")\n",
        "else:\n",
        "    print(f\"\\nâš ï¸ ëª©í‘œ ë¯¸ë‹¬ (ëª©í‘œ: 0.40, í˜„ì¬: {lora_recall_4:.4f})\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['0','1','2','3','4'],\n",
        "            yticklabels=['0','1','2','3','4'])\n",
        "plt.title('LoRA Fine-tuned Confusion Matrix', fontsize=14, weight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULT_PATH}/lora_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥\n",
        "lora_results = {\n",
        "    \"accuracy\": float(accuracy),\n",
        "    \"weighted_f1\": float(weighted_f1),\n",
        "    \"macro_f1\": float(macro_f1),\n",
        "    \"recall_per_class\": {str(i): float(recall_per_class[i]) for i in range(5)},\n",
        "    \"recall_4_baseline\": baseline_recall_4,\n",
        "    \"recall_4_improvement\": float(lora_recall_4 - baseline_recall_4)\n",
        "}\n",
        "\n",
        "with open(f'{RESULT_PATH}/lora_results.json', 'w') as f:\n",
        "    json.dump(lora_results, f, indent=2)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Phase 4: ì„±ëŠ¥ ì§€í‘œ í•´ì„ ì¶”ê°€: ì¤‘ë³µ í™•ì¸\n",
        "# ============================================\n",
        "print(f\"\\ní´ë˜ìŠ¤ë³„ Recall:\")\n",
        "for i in range(5):\n",
        "    print(f\"  í´ë˜ìŠ¤ {i}: {recall_per_class[i]:.4f}\")\n",
        "\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# ğŸ†• ì„±ëŠ¥ ì§€í‘œ í•´ì„ ì¶”ê°€\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“Š ì„±ëŠ¥ ì§€í‘œ í•´ì„\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nâœ… Weighted F1 ë†’ìŒ ({weighted_f1:.3f})\")\n",
        "print(\"   â†’ ì‹¤ì‚¬ìš© ì„±ëŠ¥ ìš°ìˆ˜\")\n",
        "print(\"   â†’ ë‹¤ìˆ˜ í´ë˜ìŠ¤(Very Positive) ì˜ ì˜ˆì¸¡í•˜ì—¬ ì „ì²´ ì»¤ë²„ë¦¬ì§€ â†‘\")\n",
        "print(f\"   â†’ ê³ ê° ë§Œì¡±ë„ ëª¨ë‹ˆí„°ë§ ì •í™•ë„: 74.7%\")\n",
        "\n",
        "print(f\"\\nâš ï¸  Macro F1 ë‚®ìŒ ({macro_f1:.3f})\")\n",
        "print(\"   â†’ ì†Œìˆ˜ í´ë˜ìŠ¤(Negative, Neutral, Positive) ì—¬ì „íˆ ì–´ë ¤ì›€\")\n",
        "print(\"   â†’ í´ë˜ìŠ¤ ê°„ ì„±ëŠ¥ ë¶ˆê· í˜• ì¡´ì¬\")\n",
        "print(f\"   â†’ íŠ¹íˆ Neutral(í´ë˜ìŠ¤ 2) ê°€ì¥ ì·¨ì•½: {recall_per_class[2]:.1%}\")\n",
        "\n",
        "# print(f\"\\nğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì \")\n",
        "# print(\"   ëª©í‘œ: Very Positive ë¦¬ë·° ìë™ ê°ì§€\")\n",
        "# print(\"   ê²°ê³¼: Weighted F1 ê°œì„ ì´ ë” ì¤‘ìš” âœ…\")\n",
        "# print(\"   ê·¼ê±°:\")\n",
        "# print(\"     - ì „ì²´ ë¦¬ë·°ì˜ 50.2%ê°€ Very Positive (í´ë˜ìŠ¤ 4)\")\n",
        "# print(\"     - í•´ë‹¹ í´ë˜ìŠ¤ Recall 8.9% â†’ 74.7% (+65.8%p)\")\n",
        "# print(f\"     - ì‹¤ë¬´ í™œìš© ê°€ëŠ¥ ìˆ˜ì¤€ ë‹¬ì„±\")\n",
        "\n",
        "print(f\"\\nğŸ“ˆ ê°œì„  ìš”ì•½\")\n",
        "print(f\"   Baseline Weighted F1: 0.1891\")\n",
        "print(f\"   LoRA Weighted F1:     {weighted_f1:.4f}\")\n",
        "print(f\"   ê°œì„ ëŸ‰:               +{weighted_f1 - 0.1891:.4f} ({(weighted_f1/0.1891 - 1)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "rpp7cYLMw029"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1-1: ì˜¤ë¥˜ ë¶„ì„ - ì–´ë–¤ ë¦¬ë·°ê°€ í‹€ë ¸ëŠ”ì§€ í™•ì¸\n",
        "# error_df = test_df.copy()\n",
        "# error_df['predicted'] = y_pred\n",
        "# error_df['correct'] = (y_true == y_pred)\n",
        "\n",
        "# # í´ë˜ìŠ¤ 2 ì˜¤ë¶„ë¥˜ ì¼€ì´ìŠ¤ ì¶”ì¶œ\n",
        "# class2_errors = error_df[\n",
        "#     (error_df['sentiment'] == 2) &\n",
        "#     (error_df['correct'] == False)\n",
        "# ].sample(20)\n",
        "\n",
        "# print(\"Neutral ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ:\")\n",
        "# for idx, row in class2_errors.iterrows():\n",
        "#     print(f\"\\nì‹¤ì œ: {row['sentiment']} | ì˜ˆì¸¡: {row['predicted']}\")\n",
        "#     print(f\"ë¦¬ë·°: {row['review_comment_message'][:100]}...\")\n",
        "\n",
        "# # 1-2: ëª¨ë¸ ì €ì¥ (Hugging Face Hub ì—…ë¡œë“œ)\n",
        "# MODEL_NAME = \"hywan/olist-sentiment-lora\"\n",
        "\n",
        "# # LoRA ì–´ëŒ‘í„°ë§Œ ì €ì¥ (540MB â†’ 3MB)\n",
        "# model.save_pretrained(f'{SAVE_PATH}/lora_adapter')\n",
        "# tokenizer.save_pretrained(f'{SAVE_PATH}/lora_adapter')\n",
        "\n",
        "# # Hubì— ì—…ë¡œë“œ\n",
        "# model.push_to_hub(MODEL_NAME)\n",
        "# tokenizer.push_to_hub(MODEL_NAME)\n",
        "\n",
        "# # ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ê³„ì‚°\n",
        "# baseline_detected = int(5024 * 0.0892)  # 448ê°œ\n",
        "# lora_detected = int(5024 * 0.7470)      # 3,752ê°œ\n",
        "\n",
        "# print(f\"âœ… ì¶”ê°€ ê°ì§€: {lora_detected - baseline_detected:,}ê°œ ê¸ì • ë¦¬ë·°\")\n",
        "# print(f\"   â†’ ê³ ê° ë§Œì¡±ë„ ëª¨ë‹ˆí„°ë§ ì»¤ë²„ë¦¬ì§€ {(lora_detected/2522)*100:.1f}%\")"
      ],
      "metadata": {
        "id": "LGx6EcJBJs7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5-1: ì˜ˆì¸¡ ê²°ê³¼ í†µí•©\n",
        "# ============================================\n",
        "# ê¸°ì¡´ ê²°ê³¼ í™œìš©\n",
        "test_result = test_df.copy()\n",
        "test_result['predicted'] = y_pred\n",
        "test_result['correct'] = (y_true == y_pred)\n",
        "\n",
        "print(f\"âœ… ë¶„ì„ ë°ì´í„°: {len(test_result):,}ê°œ\")\n",
        "print(f\"ì¹´í…Œê³ ë¦¬ ìˆ˜: {test_result['product_category_name'].nunique()}ê°œ\")\n",
        "\n",
        "# ============================================\n",
        "# Phase 5: ë¶€ì • í‚¤ì›Œë“œ & ì¹´í…Œê³ ë¦¬ ë¶„ì„ (ê°„ê²° ë²„ì „)\n",
        "# ============================================\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# í¬ë¥´íˆ¬ê°ˆì–´ í•µì‹¬ ë¶ˆìš©ì–´\n",
        "stopwords = {'de', 'a', 'o', 'que', 'e', 'nÃ£o', 'para', 'com', 'em', 'um'}\n",
        "\n",
        "def get_keywords(reviews, n=10):\n",
        "    \"\"\"í‚¤ì›Œë“œ ì¶”ì¶œ\"\"\"\n",
        "    words = []\n",
        "    for text in reviews:\n",
        "        if pd.notna(text):\n",
        "            words.extend([\n",
        "                w for w in re.findall(r'\\b[a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]+\\b', text.lower())\n",
        "                if w not in stopwords and len(w) > 3\n",
        "            ])\n",
        "    return Counter(words).most_common(n)\n",
        "\n",
        "# 1. ì „ì²´ ë¶€ì • í‚¤ì›Œë“œ Top 10\n",
        "print(\"1ï¸âƒ£ ì „ì²´ ë¶€ì • í‚¤ì›Œë“œ Top 10\")\n",
        "\n",
        "neg_reviews = test_result[test_result['sentiment'].isin([0, 1])]['review_comment_message']\n",
        "keywords = get_keywords(neg_reviews, 10)\n",
        "\n",
        "for i, (word, cnt) in enumerate(keywords, 1):\n",
        "    print(f\"{i:2}. {word:20} {cnt:4}íšŒ\")\n",
        "\n",
        "# 2. ë¶€ì • ë¹„ìœ¨ ë†’ì€ ì¹´í…Œê³ ë¦¬ Top 5\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"2ï¸âƒ£ ë¶€ì • ë¹„ìœ¨ ë†’ì€ ì¹´í…Œê³ ë¦¬ Top 5\")\n",
        "\n",
        "cat_neg = test_result.groupby('product_category_name').apply(\n",
        "    lambda x: pd.Series({\n",
        "        'total': len(x),\n",
        "        'neg_cnt': x['sentiment'].isin([0, 1]).sum(),\n",
        "        'neg_ratio': x['sentiment'].isin([0, 1]).sum() / len(x)\n",
        "    }) if len(x) >= 10 else None\n",
        ").dropna().sort_values('neg_ratio', ascending=False).head(5)\n",
        "\n",
        "for i, (cat, row) in enumerate(cat_neg.iterrows(), 1):\n",
        "    print(f\"{i}. {cat:40} {row['neg_ratio']:.1%} ({int(row['neg_cnt'])}/{int(row['total'])})\")\n",
        "\n",
        "# 3. ê° ì¹´í…Œê³ ë¦¬ë³„ ë¶€ì • í‚¤ì›Œë“œ Top 3\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"3ï¸âƒ£ ê° ì¹´í…Œê³ ë¦¬ë³„ ë¶€ì • í‚¤ì›Œë“œ Top 3\")\n",
        "\n",
        "for i, (cat, _) in enumerate(cat_neg.iterrows(), 1):\n",
        "    cat_neg_reviews = test_result[\n",
        "        (test_result['product_category_name'] == cat) &\n",
        "        (test_result['sentiment'].isin([0, 1]))\n",
        "    ]['review_comment_message']\n",
        "\n",
        "    kws = get_keywords(cat_neg_reviews, 3)\n",
        "\n",
        "    print(f\"\\n{i}. {cat}\")\n",
        "    for j, (word, cnt) in enumerate(kws, 1):\n",
        "        print(f\"   {j}) {word:15} {cnt:3}íšŒ\")"
      ],
      "metadata": {
        "id": "vilrXsvwLSjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Phase 5A: ì˜ˆì¸¡ í™•ë¥  ê¸°ë°˜ ì˜¤ë¥˜ ë¶„ì„\n",
        "# ============================================\n",
        "# í™•ë¥ ê°’ ì¶”ì¶œ\n",
        "probs = predictions.predictions  # (5024, 5) í˜•íƒœ\n",
        "test_result['max_prob'] = np.max(probs, axis=1)\n",
        "test_result['second_prob'] = np.partition(probs, -2, axis=1)[:, -2]\n",
        "test_result['prob_gap'] = test_result['max_prob'] - test_result['second_prob']\n",
        "\n",
        "print(\"âœ… ì˜ˆì¸¡ í™•ë¥  ì €ì¥ ì™„ë£Œ\")\n",
        "print(f\"í‰ê·  í™•ë¥  ì°¨ì´: {test_result['prob_gap'].mean():.3f}\")\n",
        "\n",
        "# ============================================\n",
        "# 2. Low Confidence ìƒ˜í”Œ ë¶„ì„\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“Š Confidence ë¶„í¬ ë¶„ì„\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ì •ë‹µ vs ì˜¤ë‹µ í™•ë¥  ë¹„êµ\n",
        "correct_conf = test_result[test_result['correct']]['max_prob'].mean()\n",
        "wrong_conf = test_result[~test_result['correct']]['max_prob'].mean()\n",
        "\n",
        "print(f\"\\nì •ë‹µ í‰ê·  í™•ë¥ :   {correct_conf:.3f}\")\n",
        "print(f\"ì˜¤ë‹µ í‰ê·  í™•ë¥ :   {wrong_conf:.3f}\")\n",
        "print(f\"ì°¨ì´:            {correct_conf - wrong_conf:.3f}\")\n",
        "\n",
        "# Low confidence ìƒ˜í”Œ (í™•ë¥  < 0.5)\n",
        "low_conf = test_result[test_result['max_prob'] < 0.5]\n",
        "print(f\"\\nLow Confidence (<0.5): {len(low_conf)}ê°œ ({len(low_conf)/len(test_result)*100:.1f}%)\")\n",
        "\n",
        "# ì• ë§¤í•œ ìƒ˜í”Œ (í™•ë¥  ì°¨ì´ < 0.1)\n",
        "uncertain = test_result[test_result['prob_gap'] < 0.1]\n",
        "print(f\"ì• ë§¤í•œ ìƒ˜í”Œ (<0.1 ì°¨ì´): {len(uncertain)}ê°œ ({len(uncertain)/len(test_result)*100:.1f}%)\")\n",
        "\n",
        "# ============================================\n",
        "# 3. ì• ë§¤í•œ ìƒ˜í”Œ ì§ì ‘ í™•ì¸ (10ê°œ)\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ” ì• ë§¤í•œ ìƒ˜í”Œ ì§ì ‘ í™•ì¸ (í™•ë¥  ì°¨ì´ < 0.1)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "class_names = ['Very Neg', 'Neg', 'Neutral', 'Pos', 'Very Pos']\n",
        "\n",
        "uncertain_sample = uncertain.sample(min(10, len(uncertain)), random_state=42)\n",
        "\n",
        "for idx, (_, row) in enumerate(uncertain_sample.iterrows(), 1):\n",
        "    status = \"âœ…\" if row['correct'] else \"âŒ\"\n",
        "    print(f\"\\n{idx}. {status} | ì‹¤ì œ: {class_names[row['sentiment']]} | ì˜ˆì¸¡: {class_names[row['predicted']]}\")\n",
        "    print(f\"   í™•ë¥ : {row['max_prob']:.2f} (2ë“±: {row['second_prob']:.2f}, ì°¨ì´: {row['prob_gap']:.2f})\")\n",
        "    print(f\"   ë¦¬ë·°: {row['review_comment_message'][:120]}...\")\n",
        "    print(f\"   ì¹´í…Œê³ ë¦¬: {row['product_category_name']}\")\n",
        "\n",
        "# ============================================\n",
        "# 4. ìì£¼ í‹€ë¦¬ëŠ” í´ë˜ìŠ¤ ì¡°í•©\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âš ï¸ ìì£¼ í‹€ë¦¬ëŠ” í´ë˜ìŠ¤ ì¡°í•© (Top 10)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ì˜¤ë¶„ë¥˜ë§Œ ì¶”ì¶œ\n",
        "misclassified = test_result[~test_result['correct']]\n",
        "\n",
        "# í´ë˜ìŠ¤ ì¡°í•©ë³„ ì§‘ê³„\n",
        "error_combos = misclassified.groupby(['sentiment', 'predicted']).agg({\n",
        "    'max_prob': 'mean',  # í‰ê·  í™•ë¥ \n",
        "    'review_comment_message': 'count'  # ë¹ˆë„\n",
        "}).rename(columns={'review_comment_message': 'count'}).reset_index()\n",
        "\n",
        "error_combos = error_combos.sort_values('count', ascending=False).head(10)\n",
        "\n",
        "print(f\"\\n{'ì‹¤ì œ':<12} {'ì˜ˆì¸¡':<12} {'ë¹ˆë„':<8} {'í‰ê·  í™•ë¥ ':<10}\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for _, row in error_combos.iterrows():\n",
        "    true_cls = class_names[int(row['sentiment'])]\n",
        "    pred_cls = class_names[int(row['predicted'])]\n",
        "    print(f\"{true_cls:<12} {pred_cls:<12} {int(row['count']):<8} {row['max_prob']:.3f}\")\n",
        "\n",
        "# ============================================\n",
        "# 5. ì•¡ì…˜ íƒœê·¸ ë‹¬ê¸°\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ·ï¸  ì•¡ì…˜ íƒœê·¸ ë¶„ë¥˜\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def assign_action_tag(row):\n",
        "    \"\"\"ì˜¤ë¶„ë¥˜ ìƒ˜í”Œì— ì•¡ì…˜ íƒœê·¸ ë¶€ì—¬\"\"\"\n",
        "\n",
        "    # ê³ í™•ì‹  ì˜¤ë‹µ â†’ ì¬ë¼ë²¨ë§ í›„ë³´\n",
        "    if row['max_prob'] > 0.8 and not row['correct']:\n",
        "        return 'ì¬ë¼ë²¨ë§_í›„ë³´'\n",
        "\n",
        "    # ì €í™•ì‹  â†’ ì „ì²˜ë¦¬ ê°œì„ \n",
        "    elif row['max_prob'] < 0.5:\n",
        "        return 'ì „ì²˜ë¦¬_ê°œì„ '\n",
        "\n",
        "    # ê·¹ë‹¨ ì˜¤ë¶„ë¥˜ (0â†”4, 1â†”4) â†’ ê·œì¹™ ë³´ì™„\n",
        "    elif abs(row['sentiment'] - row['predicted']) >= 3:\n",
        "        return 'ê·œì¹™_ë³´ì™„_í›„ë³´'\n",
        "\n",
        "    # ì •ë‹µ\n",
        "    elif row['correct']:\n",
        "        return 'ì •ë‹µ'\n",
        "\n",
        "    # ì¼ë°˜ ì˜¤ë‹µ\n",
        "    else:\n",
        "        return 'ì¼ë°˜_ì˜¤ë¥˜'\n",
        "\n",
        "# íƒœê·¸ ì ìš©\n",
        "test_result['action_tag'] = test_result.apply(assign_action_tag, axis=1)\n",
        "\n",
        "# íƒœê·¸ë³„ ìš”ì•½\n",
        "tag_summary = test_result['action_tag'].value_counts()\n",
        "print(\"\\nì•¡ì…˜ íƒœê·¸ë³„ ë¶„í¬:\")\n",
        "for tag, count in tag_summary.items():\n",
        "    print(f\"  {tag:20} {count:5}ê°œ ({count/len(test_result)*100:.1f}%)\")\n",
        "\n",
        "# ============================================\n",
        "# 6. ì•¡ì…˜ë³„ ìƒ˜í”Œ ì˜ˆì‹œ\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“‹ ì•¡ì…˜ë³„ ìƒ˜í”Œ ì˜ˆì‹œ\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for tag in ['ì¬ë¼ë²¨ë§_í›„ë³´', 'ì „ì²˜ë¦¬_ê°œì„ ', 'ê·œì¹™_ë³´ì™„_í›„ë³´']:\n",
        "    tag_samples = test_result[test_result['action_tag'] == tag]\n",
        "\n",
        "    if len(tag_samples) > 0:\n",
        "        print(f\"\\nğŸ”¹ {tag} ({len(tag_samples)}ê°œ)\")\n",
        "\n",
        "        for idx, (_, row) in enumerate(tag_samples.sample(min(3, len(tag_samples)), random_state=42).iterrows(), 1):\n",
        "            print(f\"\\n  {idx}. ì‹¤ì œ: {class_names[row['sentiment']]} | ì˜ˆì¸¡: {class_names[row['predicted']]} | í™•ë¥ : {row['max_prob']:.2f}\")\n",
        "            print(f\"     {row['review_comment_message'][:100]}...\")\n",
        "\n",
        "# ============================================\n",
        "# 7. ì¸ì‚¬ì´íŠ¸ ì •ë¦¬\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ’¡ ì˜¤ë¥˜ ë¶„ì„ ì¸ì‚¬ì´íŠ¸\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "relabel_cnt = (test_result['action_tag'] == 'ì¬ë¼ë²¨ë§_í›„ë³´').sum()\n",
        "preprocess_cnt = (test_result['action_tag'] == 'ì „ì²˜ë¦¬_ê°œì„ ').sum()\n",
        "rule_cnt = (test_result['action_tag'] == 'ê·œì¹™_ë³´ì™„_í›„ë³´').sum()\n",
        "\n",
        "print(f\"\\n1ï¸âƒ£ ì¬ë¼ë²¨ë§ í•„ìš” (ê³ í™•ì‹  ì˜¤ë‹µ)\")\n",
        "print(f\"   ìƒ˜í”Œ ìˆ˜: {relabel_cnt}ê°œ\")\n",
        "print(f\"   â†’ ë°ì´í„° í’ˆì§ˆ ê²€í†  í•„ìš”\")\n",
        "\n",
        "print(f\"\\n2ï¸âƒ£ ì „ì²˜ë¦¬ ê°œì„  (ì €í™•ì‹ )\")\n",
        "print(f\"   ìƒ˜í”Œ ìˆ˜: {preprocess_cnt}ê°œ\")\n",
        "print(f\"   â†’ ì§§ì€ ë¦¬ë·°, ì• ë§¤í•œ í‘œí˜„ ì²˜ë¦¬ ê°œì„ \")\n",
        "\n",
        "print(f\"\\n3ï¸âƒ£ ê·œì¹™ ë³´ì™„ (ê·¹ë‹¨ ì˜¤ë¶„ë¥˜)\")\n",
        "print(f\"   ìƒ˜í”Œ ìˆ˜: {rule_cnt}ê°œ\")\n",
        "print(f\"   â†’ ë¹„ê¼¬ëŠ” í‘œí˜„, í˜¼í•© ê°ì • ì²˜ë¦¬ í•„ìš”\")\n",
        "\n",
        "print(f\"\\n4ï¸âƒ£ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ë°©í–¥\")\n",
        "if preprocess_cnt > relabel_cnt:\n",
        "    print(\"   â†’ Dropout ì¦ê°€ (ëª¨ë¸ í™•ì‹ ë„ ì¡°ì ˆ)\")\n",
        "    print(\"   â†’ Temperature Scaling ê³ ë ¤\")\n",
        "else:\n",
        "    print(\"   â†’ ë°ì´í„° ì¦ê°• ìš°ì„  (íŠ¹íˆ í´ë˜ìŠ¤ 1, 2, 3)\")\n",
        "    print(\"   â†’ Class Weight ì¬ì¡°ì •\")\n",
        "\n",
        "# Top ì˜¤ë¥˜ ì¡°í•© ê¸°ë°˜\n",
        "top_error = error_combos.iloc[0]\n",
        "print(f\"\\n5ï¸âƒ£ ê°€ì¥ ë§ì€ ì˜¤ë¥˜\")\n",
        "print(f\"   {class_names[int(top_error['sentiment'])]} â†’ {class_names[int(top_error['predicted'])]}: {int(top_error['count'])}ê±´\")\n",
        "print(f\"   â†’ í•´ë‹¹ ì¡°í•© ì§‘ì¤‘ ë¶„ì„ í•„ìš”\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… Phase 5A ì™„ë£Œ\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥\n",
        "analysis_results = {\n",
        "    \"confidence_analysis\": {\n",
        "        \"ì •ë‹µ_í‰ê· í™•ë¥ \": float(correct_conf),\n",
        "        \"ì˜¤ë‹µ_í‰ê· í™•ë¥ \": float(wrong_conf),\n",
        "        \"low_confidence_count\": int(len(low_conf)),\n",
        "        \"uncertain_count\": int(len(uncertain))\n",
        "    },\n",
        "\n",
        "    \"action_tags\": {\n",
        "        tag: int(count)\n",
        "        for tag, count in tag_summary.items()\n",
        "    },\n",
        "\n",
        "    \"top_error_patterns\": [\n",
        "        {\n",
        "            \"ì‹¤ì œ\": class_names[int(row['sentiment'])],\n",
        "            \"ì˜ˆì¸¡\": class_names[int(row['predicted'])],\n",
        "            \"ë¹ˆë„\": int(row['count']),\n",
        "            \"í‰ê· _í™•ë¥ \": float(row['max_prob'])\n",
        "        }\n",
        "        for _, row in error_combos.head(5).iterrows()\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(f'{RESULT_PATH}/error_analysis.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(analysis_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\nâœ… ë¶„ì„ ê²°ê³¼ ì €ì¥: {RESULT_PATH}/error_analysis.json\")"
      ],
      "metadata": {
        "id": "KUGpMNZqUB67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ì˜¤ë¥˜ ë¶„ì„ ìƒ˜í”Œ ì§ì ‘ ê²€í† \n",
        "# ============================================\n",
        "\n",
        "class_names = ['Very Neg', 'Neg', 'Neutral', 'Pos', 'Very Pos']\n",
        "\n",
        "def show_samples(df, title, n=10):\n",
        "    \"\"\"ìƒ˜í”Œ nê°œ ì¶œë ¥\"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ğŸ” {title} (ì´ {len(df)}ê°œ ì¤‘ {min(n, len(df))}ê°œ)\")\n",
        "    print('='*70)\n",
        "\n",
        "    samples = df.sample(min(n, len(df)), random_state=42)\n",
        "\n",
        "    for idx, (_, row) in enumerate(samples.iterrows(), 1):\n",
        "        status = \"âœ…\" if row['correct'] else \"âŒ\"\n",
        "        print(f\"\\n[{idx}] {status} | í™•ë¥ : {row['max_prob']:.2f} | ì°¨ì´: {row['prob_gap']:.2f}\")\n",
        "        print(f\"    ì‹¤ì œ: {class_names[row['sentiment']]:12} â†’ ì˜ˆì¸¡: {class_names[row['predicted']]}\")\n",
        "        print(f\"    ğŸ“ {row['review_comment_message'][:150]}\")\n",
        "        print(f\"    ğŸ“¦ {row['product_category_name']}\")\n",
        "\n",
        "\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# 1ï¸âƒ£ ì¬ë¼ë²¨ë§ í›„ë³´ (ê³ í™•ì‹  ì˜¤ë‹µ)\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "relabel_samples = test_result[test_result['action_tag'] == 'ì¬ë¼ë²¨ë§_í›„ë³´']\n",
        "show_samples(relabel_samples, 'ì¬ë¼ë²¨ë§ í›„ë³´ - ë°ì´í„° í’ˆì§ˆ ê²€í†  í•„ìš”')\n",
        "\n",
        "\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# 2ï¸âƒ£ ì „ì²˜ë¦¬ ê°œì„  (ì €í™•ì‹ )\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "preprocess_samples = test_result[test_result['action_tag'] == 'ì „ì²˜ë¦¬_ê°œì„ ']\n",
        "show_samples(preprocess_samples, 'ì „ì²˜ë¦¬ ê°œì„  - ì§§ì€ ë¦¬ë·°/ì• ë§¤í•œ í‘œí˜„')\n",
        "\n",
        "\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# 3ï¸âƒ£ ê·œì¹™ ë³´ì™„ (ê·¹ë‹¨ ì˜¤ë¶„ë¥˜)\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "rule_samples = test_result[test_result['action_tag'] == 'ê·œì¹™_ë³´ì™„_í›„ë³´']\n",
        "show_samples(rule_samples, 'ê·œì¹™ ë³´ì™„ - ë¹„ê¼¬ëŠ” í‘œí˜„/í˜¼í•© ê°ì •', n=min(10, len(rule_samples)))\n",
        "\n",
        "\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# 4ï¸âƒ£ ê°€ì¥ ë§ì€ ì˜¤ë¥˜: Very Pos â†’ Pos\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "verypos_to_pos = test_result[\n",
        "    (test_result['sentiment'] == 4) &\n",
        "    (test_result['predicted'] == 3)\n",
        "]\n",
        "show_samples(verypos_to_pos, 'Very Pos â†’ Pos ì˜¤ë¥˜ (566ê±´)')\n",
        "\n",
        "\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# 5ï¸âƒ£ ì¶”ê°€: Very Neg â†’ Neg (2ë²ˆì§¸ë¡œ ë§ì€ ì˜¤ë¥˜)\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "veryneg_to_neg = test_result[\n",
        "    (test_result['sentiment'] == 0) &\n",
        "    (test_result['predicted'] == 1)\n",
        "]\n",
        "show_samples(veryneg_to_neg, 'Very Neg â†’ Neg ì˜¤ë¥˜ (262ê±´)')\n",
        "\n",
        "\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "# ğŸ“Š ìš”ì•½ í…Œì´ë¸”\n",
        "# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ğŸ“Š ê²€í†  ëŒ€ìƒ ìš”ì•½\")\n",
        "print('='*70)\n",
        "\n",
        "summary_data = {\n",
        "    'ì¹´í…Œê³ ë¦¬': [\n",
        "        'ì¬ë¼ë²¨ë§ í›„ë³´',\n",
        "        'ì „ì²˜ë¦¬ ê°œì„ ',\n",
        "        'ê·œì¹™ ë³´ì™„',\n",
        "        'Very Pos â†’ Pos',\n",
        "        'Very Neg â†’ Neg'\n",
        "    ],\n",
        "    'ìƒ˜í”Œ ìˆ˜': [\n",
        "        len(relabel_samples),\n",
        "        len(preprocess_samples),\n",
        "        len(rule_samples),\n",
        "        len(verypos_to_pos),\n",
        "        len(veryneg_to_neg)\n",
        "    ],\n",
        "    'ìš°ì„ ìˆœìœ„': [\n",
        "        'â­â­â­ ìµœìš°ì„ ',\n",
        "        'â­â­ ì¤‘ìš”',\n",
        "        'â­ ë‚®ìŒ',\n",
        "        'â­â­â­ ìµœìš°ì„ ',\n",
        "        'â­â­ ì¤‘ìš”'\n",
        "    ]\n",
        "}\n",
        "\n",
        "for i in range(len(summary_data['ì¹´í…Œê³ ë¦¬'])):\n",
        "    print(f\"{summary_data['ì¹´í…Œê³ ë¦¬'][i]:20} {summary_data['ìƒ˜í”Œ ìˆ˜'][i]:6}ê°œ   {summary_data['ìš°ì„ ìˆœìœ„'][i]}\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ ê²€í†  ìˆœì„œ: Very Posâ†”Pos â†’ ì¬ë¼ë²¨ë§ í›„ë³´ â†’ ì „ì²˜ë¦¬ ê°œì„ \")"
      ],
      "metadata": {
        "id": "xkVybSP2BgUq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
